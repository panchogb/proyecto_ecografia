{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.3\n",
    "VALIDATION_RATIO = 0.25\n",
    "TRAIN_RATIO = 1 - TEST_RATIO - VALIDATION_RATIO\n",
    "\n",
    "HOLDOUT_RATIO = 0.04\n",
    "\n",
    "MAX_SEQ_LENGTH = 150\n",
    "IMG_SIZE = 128\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "CLASSES = 4\n",
    "\n",
    "EPOCHS = 40#40\n",
    "\n",
    "#FEATURE_DIR = f\"\"\n",
    "#FEATURE_DIR = f\"../Features/InceptionV3_SEQUENCE/{MAX_SEQ_LENGTH}\"\n",
    "MODEL_DIR = f\"../Models/List\"\n",
    "\n",
    "\n",
    "SYS_OUT = sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor_DenseNet():\n",
    "    feature_extractor = keras.applications.DenseNet121(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.densenet.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_EXTRACTOR = build_feature_extractor_DenseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model_DENSE(num_feature_, layers):\n",
    "    layer_size = np.size(layers)\n",
    "    \n",
    "    dense_model = keras.Sequential()\n",
    "\n",
    "    dense_model.add(keras.layers.Dense(layers[0], activation='relu', name='dense_0', input_dim=num_feature_))\n",
    "\n",
    "    for i in range(1, layer_size):\n",
    "        if (layers[i] >= 64):\n",
    "            dense_model.add(keras.layers.Dropout(0.3))\n",
    "        dense_model.add(keras.layers.Dense(layers[i], name=f'dense_{i}',activation='relu'))\n",
    "\n",
    "    dense_model.add(keras.layers.Dense(CLASSES, activation=\"softmax\", name=f'dense_{layer_size}'))\n",
    "\n",
    "    dense_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return dense_model\n",
    "\n",
    "def run_experiment_DENSE(DIR, num_feature_, layers):\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        DIR, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model_DENSE(num_feature_, layers)\n",
    "\n",
    "    seq_model.load_weights(DIR)\n",
    "\n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = run_experiment_DENSE(f'../Models/Buenos/2672_DENSE_DenseNet121_[512]_SEQ0_Feature_num1024/video_classifier', 1024, np.array([512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "center_crop_layer = layers.CenterCrop(IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "def MostrarImagen(frame):\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def crop_center(frame):\n",
    "    cropped = center_crop_layer(frame[None, ...])\n",
    "    cropped = cropped.numpy().squeeze()\n",
    "    return cropped\n",
    "\n",
    "def load_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    frame = crop_center(image)\n",
    "    frame = frame[:, :, [2, 1, 0]]\n",
    "    return np.array(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = load_image(f'animation.jpg')\n",
    "#MostrarImagen(frame)\n",
    "\n",
    "frame_features = FEATURE_EXTRACTOR.predict(frame[None, :], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "[1.9849311e-05 2.1447677e-05 9.0628513e-04 9.9905235e-01]\n"
     ]
    }
   ],
   "source": [
    "probabilities = MODEL.predict(frame_features)[0]\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.000|0.000|0.000|1.000|\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.000|0.003|0.000|0.996|\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.000|0.000|0.000|1.000|\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.000|0.019|0.000|0.981|\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    frame = load_image(f'{i}.jpg')\n",
    "    frame_features = FEATURE_EXTRACTOR.predict(frame[None, :], verbose=0)\n",
    "    probabilities = MODEL.predict(frame_features)[0]\n",
    "    for num in probabilities:\n",
    "        print(f'{num:.3f}|', end='')\n",
    "    print('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
